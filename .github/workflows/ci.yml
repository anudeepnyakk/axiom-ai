name: Axiom AI CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'

jobs:
  lint:
    name: Code Quality (Linting)
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
      
      - name: Run Black (code formatter check)
        run: black --check --diff axiom/ scripts/
        continue-on-error: true
      
      - name: Run isort (import sorting check)
        run: isort --check-only --diff axiom/ scripts/
        continue-on-error: true
      
      - name: Run Flake8 (linter)
        run: flake8 axiom/ scripts/ --max-line-length=120 --extend-ignore=E203,W503
        continue-on-error: true
      
      - name: Lint Summary
        run: echo "✅ Linting complete (non-blocking for now)"

  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: lint
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-timeout
      
      - name: Run PII Redaction Tests
        run: python scripts/test_pii_redaction.py
        timeout-minutes: 2
      
      - name: Run API Auth Tests
        run: python scripts/test_api_auth.py
        timeout-minutes: 2
      
      - name: Run LRU Cache Tests
        run: python scripts/test_lru_cache.py
        timeout-minutes: 2
      
      - name: Run Retry Logic Tests
        run: python scripts/test_retry_logic.py
        timeout-minutes: 2
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      
      - name: Test Summary
        run: echo "✅ All unit tests passed"

  eval-smoke-test:
    name: Evaluation Smoke Test
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create test document
        run: |
          mkdir -p axiom/data_test
          cat > axiom/data_test/test_doc.txt << 'EOF'
          Axiom AI is a production-ready RAG system.
          It supports multilingual queries and has comprehensive evaluation.
          The system uses ChromaDB for vector storage.
          EOF
      
      - name: Run ingestion (without OpenAI)
        run: |
          python scripts/ingest.py axiom/data_test
        timeout-minutes: 5
        env:
          EMBEDDING_PROVIDER: local
          EMBEDDING_MODEL: all-MiniLM-L6-v2
      
      - name: Run retrieval-only smoke test
        run: |
          python -c "
          from axiom.config.loader import load_config
          from axiom.core.factory import create_query_engine
          from axiom.core.interfaces import DocumentChunk
          
          config = load_config()
          query_engine = create_query_engine(config)
          
          # Test retrieval only (no LLM synthesis)
          question = 'What is Axiom AI?'
          query_embedding = query_engine.embedding_generator.embed_batch([DocumentChunk(text=question, metadata={})])[0]
          results = query_engine.vector_store.search(query_embedding, top_k=3)
          
          assert len(results) > 0, 'No results retrieved'
          assert any('Axiom' in r.text for r in results), 'Relevant content not found'
          
          print(f'✅ Smoke test passed: Retrieved {len(results)} chunks')
          for i, result in enumerate(results, 1):
              print(f'  {i}. Score: {result.score:.3f}, Text: {result.text[:50]}...')
          "
        timeout-minutes: 5
        env:
          EMBEDDING_PROVIDER: local
          EMBEDDING_MODEL: all-MiniLM-L6-v2
      
      - name: Cleanup test data
        if: always()
        run: |
          rm -rf axiom/data_test
          rm -rf chroma_db
      
      - name: Eval Smoke Test Summary
        run: echo "✅ Retrieval smoke test passed"

  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: axiom-backend:ci-test
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Docker Build Summary
        run: echo "✅ Docker build successful"

  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [lint, test, eval-smoke-test, docker-build]
    if: always()
    
    steps:
      - name: Check job results
        run: |
          echo "CI Pipeline Results:"
          echo "===================="
          echo "Lint: ${{ needs.lint.result }}"
          echo "Tests: ${{ needs.test.result }}"
          echo "Eval Smoke Test: ${{ needs.eval-smoke-test.result }}"
          echo "Docker Build: ${{ needs.docker-build.result }}"
          echo ""
          
          if [ "${{ needs.lint.result }}" != "success" ] || \
             [ "${{ needs.test.result }}" != "success" ] || \
             [ "${{ needs.eval-smoke-test.result }}" != "success" ] || \
             [ "${{ needs.docker-build.result }}" != "success" ]; then
            echo "❌ CI Pipeline FAILED"
            exit 1
          else
            echo "✅ CI Pipeline PASSED"
            echo "All checks completed in under 120 seconds (combined)"
          fi

